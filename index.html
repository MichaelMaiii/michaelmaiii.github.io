<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Weijian Mai</title>

    <meta name="author" content="Weijian Mai">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Weijian Mai
                </p>
                <p>
                  
    I am a first-year PhD student in <a href="https://datascience.hku.hk/">Musketeers Foundation Institute of Data Science</a>, <a href="https://www.hku.hk/">University of Hong Kong</a>, where I am jointly supervised by <a href="https://andrewluo.net/">Andrew Luo</a> and <a href="https://www.cs.hku.hk/index.php/people/academic-staff/mayi">Yi Ma</a>. Concurrently, I hold an internship position at <a href="https://www.shlab.org.cn/">Shanghai AILab</a>, working under the mentorship of <a href="https://cf-song.github.io/">Chunfeng Song</a>. My research focuses on the intersection of NeuroAI, Generative AI, and multimodal modelsâ€”with a goal to bridge biological neural mechanisms and artificial intelligence systems for more robust, human-aligned AI capabilities.
                </p>
                <p style="text-align:center">
                  <a href="michaelmaiii@outlook.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=6nUpVxIAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/MichaelMaiii">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="michael.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="michael.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
        </a>
        <br>
        <a href="https://szymanowiczs.github.io/">Stanislaw Szymanowicz</a>,
        <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
        <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
        <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
        <a href="https://holynski.org">Aleksander Holynski</a>,
        <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
		<strong>Jonathan T. Barron</strong>,
        <a href="https://henzler.github.io">Philipp Henzler</a>
        <br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
		By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation.
        </p>
      </td>
    </tr>

    <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/ever_after.png' width=100%>
					</div>
          <img src='images/ever_before.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://half-potato.gitlab.io/posts/ever/">
			<span class="papertitle">EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis
</span>
        </a>
        <br>
				<a href="https://half-potato.gitlab.io/">Alexander Mai</a>, 
				<a href="https://phogzone.com/">Peter Hedman</a>,
				<a href="https://grgkopanas.github.io/">George Kopanas</a>,
        <a href="https://dorverbin.github.io/">Dor Verbin</a>,
        <a href="https://scholar.google.com/citations?user=ozNFrecAAAAJ&hl=en">David Futschik</a>,
        <a href="https://xharlie.github.io/">Qiangeng Xu</a>,
        <a href="https://jacobsschool.ucsd.edu/faculty/profile?id=253">Falko Kuester</a>,
				<strong>Jonathan T. Barron</strong>,
        <a href="https://www.zhangyinda.com/">Yinda Zhang</a>
				<br>
        <em>ICCV</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://half-potato.gitlab.io/posts/ever/">project page</a>
        /
        <a href="https://arxiv.org/abs/2410.01804">arXiv</a>
        <p></p>
        <p>
				Raytracing constant-density ellipsoids yields more accurate and flexible radiance fields than splatting Gaussians, and still runs in real-time.
        </p>
      </td>
    </tr>
    </table>
  </body>
</html>
